{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/rh/miniconda/envs/root_ml_latest/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from root_pandas import read_root\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.metrics.classification import _check_binary_probabilistic_predictions\n",
    "from sklearn.utils import column_or_1d\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from scripts.metrics import tagging_power_score\n",
    "from scripts.calibration import PolynomialLogisticRegression\n",
    "\n",
    "from uncertainties import ufloat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = '/fhgfs/groups/e5/lhcb/analysis/FT/NTuples/tmp_os_opt_move_to_OSOptSum17/DTT_2016_Reco16Strip26_20170607_kheinicke_TupleB_predicted-muon-classic-max3pt.root'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "totalDf = read_root('/fhgfs/groups/e5/lhcb/analysis/FT/NTuples/tmp_os_opt_move_to_OSOptSum17/DTT_2016_Reco16Strip26_20170529_jwishahi_TupleB_sweights.root',\n",
    "                    columns=['SigYield_sw', 'nCandidate'], key='Bu2JpsiKDetached')\n",
    "total_event_number = totalDf[totalDf.nCandidate == 0].SigYield_sw.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_event_number = ufloat(total_event_number, np.sqrt(total_event_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "cannot read /fhgfs/groups/e5/lhcb/analysis/FT/NTuples/tmp_os_opt_move_to_OSOptSum17/DTT_2016_Reco16Strip26_20170607_kheinicke_TupleB_predicted-muon-classic-max3pt.root",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-9d0113a5f28a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_root\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/rh/miniconda/envs/root_ml_latest/lib/python3.6/site-packages/root_pandas/readwrite.py\u001b[0m in \u001b[0;36mread_root\u001b[0;34m(paths, key, columns, ignore, chunksize, where, flatten, *args, **kwargs)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mtrees\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist_trees\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrees\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/rh/miniconda/envs/root_ml_latest/lib/python3.6/site-packages/root_numpy/_tree.py\u001b[0m in \u001b[0;36mlist_trees\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \"\"\"\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_librootnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_trees\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mroot_numpy/src/tree.pyx\u001b[0m in \u001b[0;36m_librootnumpy.list_trees (root_numpy/src/_librootnumpy.cpp:54)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mroot_numpy/src/tree.pyx\u001b[0m in \u001b[0;36m_librootnumpy.list_objects (root_numpy/src/_librootnumpy.cpp:45)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: cannot read /fhgfs/groups/e5/lhcb/analysis/FT/NTuples/tmp_os_opt_move_to_OSOptSum17/DTT_2016_Reco16Strip26_20170607_kheinicke_TupleB_predicted-muon-classic-max3pt.root"
     ]
    }
   ],
   "source": [
    "df = read_root(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.set_index(['runNumber', 'eventNumber', '__array_index'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fullDf = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.loc[df.groupby(['runNumber', 'eventNumber']).probas.idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "calibrationModel = PolynomialLogisticRegression(power=3, solver='lbfgs', n_jobs=24)\n",
    "calibrationModel.fit(df.probas.values.reshape(-1, 1), df.target)\n",
    "df['calib_probas'] = calibrationModel.predict_proba(df.probas.values.reshape(-1, 1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "isotonicModel = IsotonicRegression()\n",
    "isotonicModel.fit(df.probas, df.target)\n",
    "df['isotonic_probas'] = isotonicModel.predict(df.probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# steal this from sklearn.calibration\n",
    "\n",
    "def calibration_curve(y_true, y_prob, normalize=False, bins=10):\n",
    "    \"\"\"Compute true and predicted probabilities for a calibration curve.\n",
    "    Read more in the :ref:`User Guide <calibration>`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array, shape (n_samples,)\n",
    "        True targets.\n",
    "    y_prob : array, shape (n_samples,)\n",
    "        Probabilities of the positive class.\n",
    "    normalize : bool, optional, default=False\n",
    "        Whether y_prob needs to be normalized into the bin [0, 1], i.e. is not\n",
    "        a proper probability. If True, the smallest value in y_prob is mapped\n",
    "        onto 0 and the largest one onto 1.\n",
    "    n_bins : int\n",
    "        Number of bins. A bigger number requires more data.\n",
    "    Returns\n",
    "    -------\n",
    "    prob_true : array, shape (n_bins,)\n",
    "        The true probability in each bin (fraction of positives).\n",
    "    prob_pred : array, shape (n_bins,)\n",
    "        The mean predicted probability in each bin.\n",
    "    References\n",
    "    ----------\n",
    "    Alexandru Niculescu-Mizil and Rich Caruana (2005) Predicting Good\n",
    "    Probabilities With Supervised Learning, in Proceedings of the 22nd\n",
    "    International Conference on Machine Learning (ICML).\n",
    "    See section 4 (Qualitative Analysis of Predictions).\n",
    "    \"\"\"\n",
    "    y_true = column_or_1d(y_true)\n",
    "    y_prob = column_or_1d(y_prob)\n",
    "\n",
    "    if normalize:  # Normalize predicted values into interval [0, 1]\n",
    "        y_prob = (y_prob - y_prob.min()) / (y_prob.max() - y_prob.min())\n",
    "    elif y_prob.min() < 0 or y_prob.max() > 1:\n",
    "        raise ValueError(\"y_prob has values outside [0, 1] and normalize is \"\n",
    "                         \"set to False.\")\n",
    "\n",
    "    y_true = _check_binary_probabilistic_predictions(y_true, y_prob)\n",
    "\n",
    "    if type(bins) is int:\n",
    "        bins = np.linspace(0., 1. + 1e-8, n_bins + 1)\n",
    "        \n",
    "    binids = np.digitize(y_prob, bins) - 1\n",
    "\n",
    "    bin_sums = np.bincount(binids, weights=y_prob, minlength=len(bins))\n",
    "    bin_true = np.bincount(binids, weights=y_true, minlength=len(bins))\n",
    "    bin_total = np.bincount(binids, minlength=len(bins))\n",
    "\n",
    "    nonzero = bin_total != 0\n",
    "    prob_true = (bin_true[nonzero] / bin_total[nonzero])\n",
    "    prob_pred = (bin_sums[nonzero] / bin_total[nonzero])\n",
    "\n",
    "    return prob_true, prob_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['etas'] = np.where(df.probas > 0.5, 1 - df.probas, df.probas)\n",
    "# etaCalibrationModel = PolynomialLogisticRegression(power=3, solver='lbfgs', n_jobs=24)\n",
    "# etaCalibrationModel.fit(df.etas.values.reshape(-1, 1), ~df.target)\n",
    "# df['calib_etas'] = calibrationModel.predict_proba(df.etas.values.reshape(-1, 1))[:,1]\n",
    "df['calib_etas'] = np.where(df.calib_probas > 0.5, 1 - df.calib_probas, df.calib_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(tagging_power_score(df.etas, tot_event_number=total_event_number, sample_weight=df.SigYield_sw) * 100,\n",
    "      tagging_power_score(df.calib_etas, tot_event_number=total_event_number, sample_weight=df.SigYield_sw) * 100,\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(df.SigYield_sw * df.target).sum() / total_event_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calibration_curve(y_true, y_prob, bins=10):\n",
    "    y_true = column_or_1d(y_true)\n",
    "    y_prob = column_or_1d(y_prob)\n",
    "\n",
    "    if type(bins) is int:\n",
    "        bins = np.linspace(0, 1, bins)\n",
    "    else:\n",
    "        bins = bins[:-1]\n",
    "\n",
    "    binids = np.digitize(y_prob, bins)\n",
    "\n",
    "    bin_sums = np.bincount(binids, weights=y_prob, minlength=len(bins))\n",
    "    bin_true = np.bincount(binids, weights=y_true, minlength=len(bins))\n",
    "    bin_total = np.bincount(binids, minlength=len(bins))\n",
    "\n",
    "    nonzero = bin_total != 0\n",
    "    prob_true = bin_true[nonzero] / bin_total[nonzero]\n",
    "    prob_pred = bin_sums[nonzero] / bin_total[nonzero]\n",
    "    \n",
    "    return prob_true, prob_pred, (bin_sums[nonzero], bin_true[nonzero], bin_total[nonzero])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "percents = np.linspace(0, 100, 8)\n",
    "bins = np.percentile(df.probas, percents)\n",
    "prob_true, prob_pred, (bin_sums, bin_true, bin_total) = calibration_curve(\n",
    "    df.target, df.probas, bins=bins)\n",
    "xerrs = [prob_pred - bins[:-1], bins[1:] - prob_pred]\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot([0, 1], '--')\n",
    "xs = np.linspace(0, 1)\n",
    "ys = calibrationModel.predict_proba(xs)[:, 1]\n",
    "plt.plot(xs, ys)\n",
    "plt.errorbar(prob_pred,\n",
    "             prob_true,\n",
    "             np.sqrt(prob_true * (1 - prob_true) * bin_total) / bin_total,\n",
    "             xerrs,\n",
    "             '.',\n",
    "             label='uncalibrated',\n",
    "            )\n",
    "\n",
    "bins = np.concatenate(([df.calib_probas.min()], bins, [df.calib_probas.max()]))\n",
    "prob_true, prob_pred, (bin_sums, bin_true, bin_total) = calibration_curve(\n",
    "    df.target, df.calib_probas, bins=bins)\n",
    "xerrs = [prob_pred - bins[:-1], bins[1:] - prob_pred]\n",
    "\n",
    "plt.errorbar(prob_pred,\n",
    "             prob_true,\n",
    "             np.sqrt(prob_true * (1 - prob_true) * bin_total) / bin_total,\n",
    "             xerrs,\n",
    "             '.',\n",
    "             label='calibrated',\n",
    "            )\n",
    "plt.xlim(0.3, 0.9)\n",
    "plt.ylim(0.3, 0.9)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "percents = np.linspace(0, 100, 10)\n",
    "bins = np.percentile(df.etas, percents)\n",
    "prob_true, prob_pred, (bin_sums, bin_true, bin_total) = calibration_curve(\n",
    "    ~df.target, df.etas, bins=bins)\n",
    "xerrs = [prob_pred - bins[:-1], bins[1:] - prob_pred]\n",
    "\n",
    "_, ax1 = plt.subplots(figsize=(8, 8))\n",
    "_, histbins = np.histogram(df.etas, bins='fd')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "plt.hist(df.etas,\n",
    "         bins=histbins,\n",
    "         alpha=0.2,\n",
    "         color=colors[0],\n",
    "         )\n",
    "xs = np.linspace(0, 1)\n",
    "ys = calibrationModel.predict_proba(xs)[:, 1]\n",
    "\n",
    "plt.sca(ax1)\n",
    "plt.plot([0, 1], '--', color='grey')\n",
    "plt.plot(xs, ys, color=colors[2])\n",
    "plt.errorbar(prob_pred,\n",
    "             prob_true,\n",
    "             np.sqrt(prob_true * (1 - prob_true) * bin_total) / bin_total,\n",
    "             xerrs,\n",
    "             '.',\n",
    "             label='uncalibrated',\n",
    "             color=colors[0],\n",
    "            )\n",
    "\n",
    "bins = np.concatenate(([df.calib_etas.min()], bins, [df.calib_etas.max()]))\n",
    "bins = np.percentile(df.calib_etas, percents)\n",
    "prob_true, prob_pred, (bin_sums, bin_true, bin_total) = calibration_curve(\n",
    "    ~df.target, df.calib_etas, bins=bins)\n",
    "xerrs = [prob_pred - bins[:-1], bins[1:] - prob_pred]\n",
    "\n",
    "_, histbins = np.histogram(df.etas, bins='fd')\n",
    "plt.sca(ax2)\n",
    "plt.hist(df.calib_etas,\n",
    "         bins=histbins,\n",
    "         alpha=0.2,\n",
    "         color=colors[1],\n",
    "         )\n",
    "plt.sca(ax1)\n",
    "\n",
    "plt.errorbar(prob_pred,\n",
    "             prob_true,\n",
    "             np.sqrt(prob_true * (1 - prob_true) * bin_total) / bin_total,\n",
    "             xerrs,\n",
    "             '.',\n",
    "             label='calibrated',\n",
    "             color=colors[1],\n",
    "            )\n",
    "plt.xlim(0.1, 0.55)\n",
    "plt.ylim(0.1, 0.55)\n",
    "plt.xlabel(r'$\\eta$')\n",
    "plt.ylabel(r'$\\omega$')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['decision'] = -df.B_OSMuonDev_TagPartsFeature_Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.reset_index().to_root('plainq.root')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.decision *= -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.reset_index().to_root('invertedplainq.root')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.etas.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(100 * (1 - 2 * (~df.target * df.SigYield_sw).sum() / df.SigYield_sw.sum())**2 * df.SigYield_sw.sum() / total_event_number)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
