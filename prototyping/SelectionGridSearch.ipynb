{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from root_pandas import read_root, to_root\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cross_validation import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from itertools import islice\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import ROOT\n",
    "\n",
    "from uncertainties import ufloat\n",
    "\n",
    "from collections import OrderedDict\n",
    "from scripts.metrics import tagging_power_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (10, 10)\n",
    "plt.rcParams['font.size'] = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = '/home/kheinicke/tank/flavourtagging/'\n",
    "filenames = [\n",
    "    data_dir + 'Bu2JpsiK_mu-k-e-TrainingTuple_2011_MD_sweighted_kheinick.root',\n",
    "    data_dir + 'Bu2JpsiK_mu-k-e-TrainingTuple_2011_MU_sweighted_kheinick.root',\n",
    "    data_dir + 'Bu2JpsiK_mu-k-e-TrainingTuple_2012_MD_sweighted_kheinick.root',\n",
    "    data_dir + 'Bu2JpsiK_mu-k-e-TrainingTuple_2012_MU_sweighted_kheinick.root',\n",
    "]\n",
    "chunksize = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# just define some keyword arguments for read_root in a separate dict\n",
    "data_kwargs = dict(\n",
    "    key='DecayTree',  # the tree name\n",
    "    columns=['B_OS_Muon*',  # all branches that should be read\n",
    "             'B_ID',\n",
    "             'B_PT',\n",
    "             'SigYield_sw',\n",
    "             'runNumber',\n",
    "             'eventNumber',\n",
    "            ],\n",
    "    chunksize=chunksize,  # this will create a generator, yielding subsets with 'chunksize' of the data\n",
    "    where='(B_LOKI_MASS_JpsiConstr_NoPVConstr>0)',  # a ROOT where selection, does not work with array-variables\n",
    "    flatten=True  # will flatten the data in the dimension of the first given column\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# still have to use plain ROOT to get the number of entries...\n",
    "n_entries = 0\n",
    "for fn in filenames:\n",
    "    f = ROOT.TFile(fn)\n",
    "    t = f.Get('DecayTree')\n",
    "    n_entries += t.GetEntries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:30<00:00,  1.01s/it]\n"
     ]
    }
   ],
   "source": [
    "# This will read chunks of the data inside a list comprehension and then concat those to a big dataframe\n",
    "# note that tqdm is just some boilerplate to generate a progressbar\n",
    "# df = pd.concat([df for df in tqdm(read_root(filenames, **data_kwargs), total=n_entries/chunksize)])\n",
    "\n",
    "# only use the first 10 chunks to speed up read process and reduce RAM pressure for development\n",
    "df = pd.concat([df for df in tqdm(islice(read_root(filenames, **data_kwargs), 30), total=30)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['target'] = np.sign(df.B_ID) == np.sign(df.B_OS_Muon_ID)\n",
    "df.rename(columns=dict(zip(df.columns, [c.replace('B_OS_Muon', 'tp') for c in df.columns])), inplace=True)\n",
    "df['tp_ABS_RecVertexIP'] = np.abs(df.tp_RecVertexIP)\n",
    "df['event_id'] = df.runNumber.apply(str) + '_' + df.eventNumber.apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3874783 entries, 0 to 127832\n",
      "Data columns (total 39 columns):\n",
      "tp_DEC                 int32\n",
      "tp_PROB                float64\n",
      "tp_PARTICLES_NUM       int32\n",
      "tp_ABSID               float32\n",
      "tp_partP               float32\n",
      "tp_partPt              float32\n",
      "tp_partlcs             float32\n",
      "tp_BPVIPCHI2           float32\n",
      "tp_TRTYPE              float32\n",
      "tp_PIDmu               float32\n",
      "tp_IPPU                float32\n",
      "tp_ghostProb           float32\n",
      "tp_PIDNNm              float32\n",
      "tp_PROBNNpi            float32\n",
      "tp_PROBNNe             float32\n",
      "tp_PROBNNk             float32\n",
      "tp_PROBNNp             float32\n",
      "tp_PP_HASMUONPID       float32\n",
      "tp_PP_MuonPIDStatus    float32\n",
      "tp_IsSignalDaughter    float32\n",
      "tp_Signal_P            float32\n",
      "tp_minPhiDistance      float32\n",
      "tp_MuonPIDIsMuon       float32\n",
      "tp_RecVertexIP         float32\n",
      "tp_mult                float32\n",
      "tp_ptB                 float32\n",
      "tp_IPs                 float32\n",
      "tp_KEY                 float32\n",
      "tp_Q                   float32\n",
      "tp_ID                  float32\n",
      "B_ID                   int32\n",
      "B_PT                   float64\n",
      "SigYield_sw            float64\n",
      "runNumber              uint32\n",
      "eventNumber            uint64\n",
      "__array_index          int64\n",
      "target                 bool\n",
      "tp_ABS_RecVertexIP     float32\n",
      "event_id               object\n",
      "dtypes: bool(1), float32(28), float64(3), int32(3), int64(1), object(1), uint32(1), uint64(1)\n",
      "memory usage: 878.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the meta classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this is the list of BDT variables formerly used\n",
    "classic_MVA_features = ['tp_' + c for c in [\n",
    "    'partP',\n",
    "    'partPt',\n",
    "    'IPPU',\n",
    "    'ghostProb',\n",
    "    'PIDNNm',\n",
    "    'ABS_RecVertexIP',\n",
    "    'mult',\n",
    "    'ptB',\n",
    "    'IPs',\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_event_number(df, weight_column='SigYield_sw'):\n",
    "    \"\"\" Use weighted sums\n",
    "    \"\"\"\n",
    "    return np.sum(df.groupby('event_id')[weight_column].first())  # max, min, mean, first should give the same values here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CutBasedXGBClassifier(XGBClassifier):\n",
    "    def __init__(self, max_depth=3, learning_rate=0.1, n_estimators=100,\n",
    "                 silent=True, objective=\"reg:linear\",\n",
    "                 nthread=-1, gamma=0, min_child_weight=1, max_delta_step=0,\n",
    "                 subsample=1, colsample_bytree=1, colsample_bylevel=1,\n",
    "                 reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
    "                 base_score=0.5, seed=0, missing=None,\n",
    "                 P_column='tp_partP', P_cut=0,\n",
    "                 PT_column='tp_partPt', PT_cut=1.1,\n",
    "                 phiDistance_column='tp_minPhiDistance', phiDistance_cut=0.005,\n",
    "                 MuonPIDIsMuon_column='tp_MuonPIDIsMuon', MuonPIDIsMuon_cut=1,\n",
    "                 mvaFeatures=None, only_max_pt=True, event_identifier_column='event_id',\n",
    "                 IsSignalDaughter_column='tp_IsSignalDaughter', IsSignalDaughter_cut=0,\n",
    "                 RecVertexIPs_column='tp_ABS_RecVertexIP', RecVertexIPs_cut=0,\n",
    "                 TRCHI2DOF_column='tp_partlcs', TRCHI2DOF_cut=3,\n",
    "                 TRGHP_column='tp_ghostProb', TRGHP_cut=0.4,\n",
    "                 PROBNNmu_column='tp_PIDNNm', PROBNNmu_cut=0.35,\n",
    "                 PROBNNpi_column='tp_PROBNNpi', PROBNNpi_cut=0.8,\n",
    "                 PROBNNe_column='tp_PROBNNe', PROBNNe_cut=0.8,\n",
    "                 PROBNNk_column='tp_PROBNNk', PROBNNk_cut=0.8,\n",
    "                 PROBNNp_column='tp_PROBNNp', PROBNNp_cut=0.8,\n",
    "                 IPPUs_column='tp_IPPU', IPPUs_cut=3,\n",
    "                ):\n",
    "        self.cut_parameters = ['P', 'PT', 'phiDistance', 'MuonPIDIsMuon',\n",
    "                               'IsSignalDaughter', 'TRCHI2DOF', 'TRGHP',\n",
    "                               'PROBNNmu', 'PROBNNpi', 'PROBNNe', 'PROBNNk',\n",
    "                               'PROBNNp', 'IPPUs', 'RecVertexIPs',\n",
    "                              ]\n",
    "        for cp in self.cut_parameters:\n",
    "            setattr(self, '{}_cut'.format(cp), locals()['{}_cut'.format(cp)])\n",
    "            setattr(self, '{}_column'.format(cp), locals()['{}_column'.format(cp)])\n",
    "        self.mvaFeatures = mvaFeatures\n",
    "        self.only_max_pt = only_max_pt\n",
    "        self.event_identifier_column = event_identifier_column\n",
    "        self.fit_status_ = True\n",
    "        super(CutBasedXGBClassifier, self).__init__(max_depth=max_depth, learning_rate=learning_rate,\n",
    "                                                    n_estimators=n_estimators, silent=silent, objective=objective,\n",
    "                                                    nthread=nthread, gamma=gamma, min_child_weight=min_child_weight,\n",
    "                                                    max_delta_step=max_delta_step,\n",
    "                                                    subsample=subsample, colsample_bytree=colsample_bytree,\n",
    "                                                    colsample_bylevel=colsample_bylevel,\n",
    "                                                    reg_alpha=reg_alpha, reg_lambda=reg_lambda,\n",
    "                                                    scale_pos_weight=scale_pos_weight,\n",
    "                                                    base_score=base_score, seed=seed, missing=None)\n",
    "\n",
    "    def select(self, X, y=None):\n",
    "        print('Applying selection')\n",
    "        len_before = get_event_number(X)\n",
    "        selection = ((X[self.P_column] > self.P_cut)\n",
    "                     & (X[self.PT_column] > self.PT_cut)\n",
    "                     & (X[self.phiDistance_column] > self.phiDistance_cut)\n",
    "                     & (X[self.MuonPIDIsMuon_column] == self.MuonPIDIsMuon_cut)\n",
    "                     & (X[self.IsSignalDaughter_column] == self.IsSignalDaughter_cut)\n",
    "                     & (X[self.TRCHI2DOF_column] < self.TRCHI2DOF_cut)\n",
    "                     & (X[self.TRGHP_column] < self.TRGHP_cut)\n",
    "                     & (X[self.PROBNNmu_column] > self.PROBNNmu_cut)\n",
    "                     & (X[self.PROBNNpi_column] < self.PROBNNpi_cut)\n",
    "                     & (X[self.PROBNNe_column] < self.PROBNNe_cut)\n",
    "                     & (X[self.PROBNNk_column] < self.PROBNNk_cut)\n",
    "                     & (X[self.PROBNNp_column] < self.PROBNNp_cut)\n",
    "                     & (X[self.IPPUs_column] > self.IPPUs_cut)\n",
    "                     & (X[self.RecVertexIPs_column] > self.RecVertexIPs_cut)\n",
    "                    )\n",
    "        X = X[selection]\n",
    "        if y is not None:\n",
    "            y = y[selection]\n",
    "        \n",
    "        if self.only_max_pt:\n",
    "            X.reset_index(drop=True, inplace=True)\n",
    "            max_pt_indices = X.groupby(self.event_identifier_column)[self.PT_column].idxmax()\n",
    "            X = X.iloc[max_pt_indices]\n",
    "            if y is not None:\n",
    "                y.reset_index(drop=True, inplace=True)\n",
    "                y = y.iloc[max_pt_indices]\n",
    "\n",
    "        len_after = get_event_number(X)\n",
    "        self.efficiency_ = len_after / len_before\n",
    "\n",
    "        if self.mvaFeatures:\n",
    "            X = X[self.mvaFeatures]\n",
    "        \n",
    "        if y is not None:\n",
    "            return X, y\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "    def get_params(self, deep=False):\n",
    "        params = super(CutBasedXGBClassifier, self).get_params(deep=deep)\n",
    "        for cp in self.cut_parameters:\n",
    "            params['{}_cut'.format(cp)] = getattr(self, '{}_cut'.format(cp))\n",
    "            params['{}_column'.format(cp)] = getattr(self, '{}_column'.format(cp))\n",
    "        params['mvaFeatures'] = self.mvaFeatures\n",
    "        params['only_max_pt'] = self.only_max_pt\n",
    "        params['event_identifier_column'] = self.event_identifier_column\n",
    "        return params\n",
    "\n",
    "    def set_params(self, **kwargs):\n",
    "        for cp in self.cut_parameters:\n",
    "            cutname = '{}_cut'.format(cp)\n",
    "            if kwargs.has_key(cutname) and kwargs[cutname] is not None:\n",
    "                setattr(self, cutname, kwargs.pop(cutname))\n",
    "        for other_param in ['mvaFeatures', 'only_max_pt', 'event_identifier_column']:\n",
    "            if kwargs.has_key(other_param) and kwargs[other_param] is not None:\n",
    "                setattr(self, other_param, kwargs.pop(other_param))\n",
    "        super(CutBasedXGBClassifier, self).set_params(**kwargs)\n",
    "        return self\n",
    "\n",
    "    def fit(self, X, y, eval_set=None, **kwargs):\n",
    "        if eval_set is not None:\n",
    "            eval_set = [self.select(X_, y_) for X_, y_ in eval_set]\n",
    "        X_, y_ = self.select(X, y)\n",
    "        return super(CutBasedXGBClassifier, self).fit(X_, y_, eval_set=eval_set, **kwargs)\n",
    "\n",
    "    def predict_proba(self, data, **kwargs):\n",
    "        print('Predicting probas')\n",
    "        return super(CutBasedXGBClassifier, self).predict_proba(self.select(data), **kwargs)\n",
    "\n",
    "    def score(self, X, y, sample_weight=None):\n",
    "        print('Calculating tagging power')\n",
    "        probas = self.predict_proba(X)[:,1]\n",
    "        sc = tagging_power_score(probas, efficiency=self.efficiency_, sample_weight=sample_weight)\n",
    "        return sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SelectionKFold(KFold):\n",
    "    def __init__(self, y, n_folds=3, shuffle=False, random_state=None):\n",
    "        self.y = y\n",
    "        self.unique_events = self.y.event_id.unique()\n",
    "        self.raw_indices = np.arange(len(y))\n",
    "        super(SelectionKFold, self).__init__(len(np.unique(y.event_id)), n_folds=n_folds,\n",
    "                                             shuffle=shuffle, random_state=random_state)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for train_indices, test_indices in super(SelectionKFold, self).__iter__():\n",
    "            print('Yielding split')\n",
    "            yield (self.raw_indices[self.y.event_id.isin(self.unique_events[train_indices]).values],\n",
    "                   self.raw_indices[self.y.event_id.isin(self.unique_events[test_indices]).values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['103146_64788876', '103146_7913757', '103146_66250073', ...,\n",
       "       '97354_2562534720', '97354_2570553414', '97354_2577687734'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.event_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "skf = SelectionKFold(df, n_folds=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yielding split\n",
      "(array([16103434, 16103435, 16103436, ..., 32726568, 32726569, 32726570]), array([       0,        1,        2, ..., 16103431, 16103432, 16103433]))\n",
      "Yielding split\n",
      "(array([       0,        1,        2, ..., 16103431, 16103432, 16103433]), array([16103434, 16103435, 16103436, ..., 32726568, 32726569, 32726570]))\n",
      "CPU times: user 10.4 s, sys: 0 ns, total: 10.4 s\n",
      "Wall time: 10.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for a in skf:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cbxgb = CutBasedXGBClassifier(mvaFeatures=classic_MVA_features, max_depth=5,\n",
    "                              n_estimators=300, learning_rate=0.01, seed=10,\n",
    "#                               **best_params\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying selection\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CutBasedXGBClassifier(IPPUs_column='tp_IPPU', IPPUs_cut=3,\n",
       "           IsSignalDaughter_column='tp_IsSignalDaughter',\n",
       "           IsSignalDaughter_cut=0, MuonPIDIsMuon_column='tp_MuonPIDIsMuon',\n",
       "           MuonPIDIsMuon_cut=1, PROBNNe_column='tp_PROBNNe',\n",
       "           PROBNNe_cut=0.8, PROBNNk_column='tp_PROBNNk', PROBNNk_cut=0.8,\n",
       "           PROBNNmu_column='tp_PIDNNm', PROBNNmu_cut=0.35,\n",
       "           PROBNNp_column='tp_PROBNNp', PROBNNp_cut=0.8,\n",
       "           PROBNNpi_column='tp_PROBNNpi', PROBNNpi_cut=0.8,\n",
       "           PT_column='tp_partPt', PT_cut=1.1, P_column='tp_partP', P_cut=0,\n",
       "           RecVertexIPs_column='tp_ABS_RecVertexIP', RecVertexIPs_cut=0,\n",
       "           TRCHI2DOF_column='tp_partlcs', TRCHI2DOF_cut=3,\n",
       "           TRGHP_column='tp_ghostProb', TRGHP_cut=0.4, base_score=0.5,\n",
       "           colsample_bylevel=1, colsample_bytree=1,\n",
       "           event_identifier_column='event_id', gamma=0, learning_rate=0.01,\n",
       "           max_delta_step=0, max_depth=5, min_child_weight=1, missing=None,\n",
       "           mvaFeatures=['tp_partP', 'tp_partPt', 'tp_IPPU', 'tp_ghostProb', 'tp_PIDNNm', 'tp_ABS_RecVertexIP', 'tp_mult', 'tp_ptB', 'tp_IPs'],\n",
       "           n_estimators=300, nthread=-1, objective='reg:linear',\n",
       "           only_max_pt=True, phiDistance_column='tp_minPhiDistance',\n",
       "           phiDistance_cut=0.005, reg_alpha=0, reg_lambda=1,\n",
       "           scale_pos_weight=1, seed=10, silent=True, subsample=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbxgb.fit(df, df.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating tagging power\n",
      "Predicting probas\n",
      "Applying selection\n",
      "tagging power = 0.74%\n"
     ]
    }
   ],
   "source": [
    "print('tagging power = {:.2f}%'.format(cbxgb.score(df, df.target) * 100))\n",
    "# print('tagging power test = {:.2f}%'.format(cbxgb.score(test_data, test_labels) * 100))\n",
    "# print('tagging power train = {:.2f}%'.format(cbxgb.score(train_data, train_labels) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140242835526352"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(skf.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = df.iloc[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140241657959184"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05533317299476564"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbxgb.efficiency_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid_searcher = RandomizedSearchCV(CutBasedXGBClassifier(nthread=1, mvaFeatures=classic_MVA_features,\n",
    "                                                         n_estimators=300),\n",
    "                                   {\n",
    "        'P_cut': np.linspace(2, 5, 10),\n",
    "        'PT_cut': np.linspace(0, 2, 10),\n",
    "        'phiDistance_cut': np.linspace(0, 0.5, 10),\n",
    "        'MuonPIDIsMuon_cut': [0, 1],\n",
    "        'TRGHP_cut': np.linspace(0, 0.6, 10),\n",
    "        'IPPUs_cut': np.linspace(1, 4, 10),\n",
    "        'n_estimators': [200, 300, 400],\n",
    "    }, n_iter=300, error_score=0, verbose=1, cv=skf, n_jobs=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 300 candidates, totalling 600 fits\n",
      "Yielding split\n",
      "Yielding split\n",
      "Yielding split\n",
      "Yielding split\n",
      "Yielding split\n",
      "Yielding split\n"
     ]
    }
   ],
   "source": [
    "grid_searcher.fit(df, df.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| chunks | nfits | xgb jobs | grid search jobs | time/min |\n",
    "|--------|-------|----------|------------------|------|\n",
    "| 30     | 32    | 1        | 1                | 2.3  |\n",
    "|        |       | 1        | 32               | 2.3  |\n",
    "|        |       | 32       | 1                | 3.4  |\n",
    "| all    | 32    | 1        | 32               | ?    |\n",
    "|        | 2     | 1        | (32)             | 2.8  |\n",
    "|        | 6     | 1        | (32)             | 6.1  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_searcher.best_score_ * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_searcher.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_index = np.nanargmax([sc[1] for sc in grid_searcher.grid_scores_])\n",
    "best_score = grid_searcher.grid_scores_[best_index]\n",
    "print('tagging power {}% with params\\n{}'.format(100 * ufloat(np.mean(best_score[2]), np.std(best_score[2])),\n",
    "                                                 best_score[0]))\n",
    "best_params = best_score[0]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
