{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from root_pandas import read_root\n",
    "import root_numpy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_recall_curve\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from itertools import islice\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import ROOT\n",
    "\n",
    "from scripts.data_preparation import add_target_column, concat_df_chunks\n",
    "\n",
    "from rep.metaml import GridOptimalSearchCV, RegressionParameterOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (12, 7)\n",
    "plt.rcParams['font.size'] = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = '/home/kheinicke/tank/flavourtagging/'\n",
    "filenames = [\n",
    "    data_dir + 'Bu2JpsiK_MuonTrainingTuple_2012_MD_sweighted_kheinick.root',\n",
    "    data_dir + 'Bu2JpsiK_MuonTrainingTuple_2012_MU_sweighted_kheinick.root',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Dataset\n",
    "Since these files are very huge and ROOT does a lot of comprimation, having the whole dataset in RAM is not possible too easy. Therefore for now only use 100k Events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_rows = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_data = read_root(filenames,\n",
    "                      key='DecayTree',\n",
    "                      columns=['B_OS_Muon*', 'B_*', 'SigYield_sw', 'BkgYield_sw'],\n",
    "                      ignore=['B_ENDVERTEX_COV_',\n",
    "                              'B_OWNPV_COV_',\n",
    "                              'B_TOPPV_COV_',\n",
    "                              'B_OS_E*',\n",
    "                              'B_OS_K*',\n",
    "                              'B_All*',\n",
    "                              'B_Hlt*',\n",
    "                              'B_L0*',\n",
    "                            ],\n",
    "                      stop=num_rows,\n",
    "                      where='(B_LOKI_MASS_JpsiConstr_NoPVConstr>0)',\n",
    "                      flatten=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add the target column\n",
    "full_data['target'] = np.sign(full_data.B_ID) == np.sign(full_data.B_OS_Muon_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_data.replace([-np.inf, np.inf], np.nan, inplace=True)\n",
    "full_data.dropna(inplace=True)\n",
    "labels = full_data['target'].copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ncols = 3\n",
    "muon_columns = [f for f in full_data.columns if f.startswith('B_OS_Muon')]\n",
    "nrows = np.ceil(len(muon_columns)/ncols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(16, nrows * 4))\n",
    "# for i, f in enumerate(muon_columns):\n",
    "#     plt.subplot(nrows, ncols, i+1)\n",
    "#     _, bins = np.histogram(full_data[f], 50)\n",
    "#     full_data[labels==True][f].hist(bins=bins, alpha=0.5, label='True', normed=True)\n",
    "#     full_data[labels==False][f].hist(bins=bins, alpha=0.5, label='False', normed=True)\n",
    "#     plt.title(f[:24])\n",
    "#     plt.legend(loc='best')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimal Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = train_test_split(full_data[muon_columns], labels, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def avg_dilution(labels, prediction, threshhold=0.5):\n",
    "    wrong_tags = labels != (prediction > threshhold)\n",
    "    omega = np.sum(wrong_tags) / len(labels)\n",
    "    return 1 - 2*omega\n",
    "\n",
    "\n",
    "def tagging_power(efficiency, dilution):\n",
    "    return efficiency * dilution ** 2\n",
    "\n",
    "\n",
    "def tagging_power_scorer(estimator, X, y):\n",
    "    probas = estimator.predict_proba(X)[:,1]\n",
    "    dilution = avg_dilution(y, probas)\n",
    "    return tagging_power(efficiency, dilution)\n",
    "\n",
    "\n",
    "def tp_scorer(y_true, probas, sample_weight=None):\n",
    "    dilution = avg_dilution(y_true, probas)\n",
    "    print('Dilution {}'.format(dilution))\n",
    "    return tagging_power(1, dilution)\n",
    "\n",
    "\n",
    "def tagging_power_curve(y_true, probas):\n",
    "    xs = np.linspace(0, 1, 100)\n",
    "    ys = [tagging_power(efficiency, avg_dilution(y_true, probas, thresh)) for thresh in xs]\n",
    "    return np.array(ys), xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid = {\n",
    "    'max_depth': np.arange(1, 5),\n",
    "    'learning_rate': np.linspace(0.1, 0.5, 10),\n",
    "    'n_estimators': np.arange(5, 50, 5),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rep.metaml import ClassificationFoldingScorer\n",
    "from rep.report.metrics import RocAuc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scorer = ClassificationFoldingScorer(RocAuc())\n",
    "parameter_generator = RegressionParameterOptimizer(grid, n_attempts=20, n_evaluations=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_finder = GridOptimalSearchCV(xgb.XGBClassifier(nthread=4),\n",
    "                                  parameter_generator,\n",
    "                                  scorer,\n",
    "                                  parallel_profile='threads-4'\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search in 4 threads\n",
      "4 evaluations done\n",
      "8 evaluations done\n",
      "12 evaluations done\n",
      "16 evaluations done\n",
      "20 evaluations done\n",
      "24 evaluations done\n",
      "28 evaluations done\n",
      "32 evaluations done\n",
      "36 evaluations done\n",
      "40 evaluations done\n",
      "44 evaluations done\n",
      "48 evaluations done\n",
      "52 evaluations done\n",
      "56 evaluations done\n",
      "60 evaluations done\n",
      "64 evaluations done\n",
      "68 evaluations done\n",
      "72 evaluations done\n",
      "76 evaluations done\n",
      "80 evaluations done\n",
      "84 evaluations done\n",
      "88 evaluations done\n",
      "92 evaluations done\n",
      "96 evaluations done\n",
      "100 evaluations done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<rep.metaml.gridsearch.GridOptimalSearchCV at 0x7f3a3c0416a0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_finder.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('n_estimators', 35),\n",
       "             ('learning_rate', 0.41111111111111109),\n",
       "             ('max_depth', 4)])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_finder.params_generator.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
